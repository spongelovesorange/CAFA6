import os
import pandas as pd
import numpy as np
import csv
from goatools.obo_parser import GODag
from tqdm import tqdm

# ================= é…ç½® =================
INPUT_SUBMISSION = 'submission.tsv'
OUTPUT_SUBMISSION = 'submission_propagated.tsv'
OBO_PATH = 'data/Train/go-basic.obo'

# ä¼ æ’­å‚æ•°
MAX_PREDS_PER_PROTEIN = 1500
PROPAGATION_DECAY = 0.95  # çˆ¶èŠ‚ç‚¹ç»§æ‰¿95%çš„å­èŠ‚ç‚¹åˆ†æ•°
FINAL_THRESHOLD = 0.01    # æœ€ç»ˆé˜ˆå€¼

def main():
    print("="*60)
    print("CAFA6 GO Hierarchy Propagation")
    print("="*60)
    
    # 1. åŠ è½½GOå›¾
    print(f"\n>>> Loading GO DAG from {OBO_PATH}...")
    if not os.path.exists(OBO_PATH):
        raise FileNotFoundError(f"âŒ GO OBO file not found: {OBO_PATH}")
    
    go_dag = GODag(OBO_PATH)
    print(f"âœ… GO DAG loaded: {len(go_dag)} terms")
    
    # 2. é¢„è®¡ç®—ç¥–å…ˆï¼ˆåŠ é€Ÿï¼‰
    print("\n>>> Pre-computing ancestors map...")
    term_ancestors = {}
    for term in tqdm(go_dag):
        term_ancestors[term] = go_dag[term].get_all_parents()
    print(f"âœ… Ancestors computed")
    
    # 3. è¯»å–åŸå§‹æäº¤
    print(f"\n>>> Reading raw submission: {INPUT_SUBMISSION}...")
    if not os.path.exists(INPUT_SUBMISSION):
        raise FileNotFoundError(f"âŒ Input file not found! Please run inference_m2.py first.")
    
    df = pd.read_csv(INPUT_SUBMISSION, sep='\t', names=['id', 'term', 'score'])
    print(f"âœ… Input: {len(df):,} predictions for {df['id'].nunique():,} proteins")
    
    # 4. è¿‡æ»¤æ— æ•ˆGO terms
    valid_terms = set(term_ancestors.keys())
    before_filter = len(df)
    df = df[df['term'].isin(valid_terms)]
    after_filter = len(df)
    
    if before_filter != after_filter:
        print(f"âš ï¸  Filtered {before_filter - after_filter} predictions with invalid GO terms")
    
    # 5. ä¼ æ’­
    grouped = df.groupby('id')
    new_rows = []
    
    print(f"\n>>> Propagating scores (Child â†’ Parent with {PROPAGATION_DECAY} decay)...")
    for pid, group in tqdm(grouped, total=len(grouped)):
        # å½“å‰è›‹ç™½çš„é¢„æµ‹
        scores = dict(zip(group['term'], group['score']))
        final_scores = scores.copy()
        
        # ä¼ æ’­åˆ°ç¥–å…ˆ
        predicted_terms = list(scores.keys())
        for term in predicted_terms:
            score = scores[term]
            parents = term_ancestors.get(term, [])
            
            for parent in parents:
                # çˆ¶èŠ‚ç‚¹åˆ†æ•° = max(å½“å‰åˆ†æ•°, å­èŠ‚ç‚¹åˆ†æ•° Ã— è¡°å‡ç³»æ•°)
                propagated_score = score * PROPAGATION_DECAY
                final_scores[parent] = max(final_scores.get(parent, 0.0), propagated_score)
        
        # æ’åºå¹¶é™åˆ¶æ•°é‡
        sorted_terms = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)
        sorted_terms = sorted_terms[:MAX_PREDS_PER_PROTEIN]
        
        # åº”ç”¨æœ€ç»ˆé˜ˆå€¼
        for term, score in sorted_terms:
            if score >= FINAL_THRESHOLD:
                new_rows.append([pid, term, f"{score:.3f}"])
    
    print(f"âœ… Propagation complete")
    
    # 6. ä¿å­˜ç»“æœ
    print(f"\n>>> Saving propagated results to {OUTPUT_SUBMISSION}...")
    with open(OUTPUT_SUBMISSION, 'w', newline='') as f:
        writer = csv.writer(f, delimiter='\t')
        writer.writerows(new_rows)
    print(f"âœ… File saved")
    
    # 7. éªŒè¯
    print("\n" + "="*60)
    print("VALIDATION REPORT")
    print("="*60)
    
    df_final = pd.read_csv(OUTPUT_SUBMISSION, sep='\t', names=['id', 'term', 'score'])
    
    print(f"\nğŸ“Š Statistics:")
    print(f"  Total predictions: {len(df_final):,}")
    print(f"  Unique proteins: {df_final['id'].nunique():,}")
    print(f"  Avg preds/protein: {len(df_final) / df_final['id'].nunique():.1f}")
    print(f"  Score range: [{df_final['score'].min():.3f}, {df_final['score'].max():.3f}]")
    print(f"  File size: {os.path.getsize(OUTPUT_SUBMISSION) / (1024*1024):.1f} MB")
    
    counts = df_final.groupby('id').size()
    print(f"\nğŸ“ˆ Predictions per protein:")
    print(f"  Min: {counts.min()}")
    print(f"  Max: {counts.max()}")
    print(f"  Median: {counts.median():.0f}")
    print(f"  Mean: {counts.mean():.1f}")
    
    # å¯¹æ¯”ä¼ æ’­å‰å
    print(f"\nğŸ“Š Before vs After Propagation:")
    print(f"  Before: {len(df):,} predictions")
    print(f"  After:  {len(df_final):,} predictions")
    print(f"  Change: +{len(df_final) - len(df):,} ({(len(df_final)/len(df) - 1)*100:+.1f}%)")
    
    # åˆè§„æ€§æ£€æŸ¥
    print(f"\nâœ… Compliance Check:")
    if counts.max() <= 1500:
        print("  âœ… All proteins within 1500 prediction limit")
    else:
        print(f"  âŒ {(counts > 1500).sum()} proteins exceed 1500!")
    
    print("\n" + "="*60)
    print(f"âœ… SUBMISSION READY: {OUTPUT_SUBMISSION}")
    print("="*60)
    print("\nNext steps:")
    print("  1. Download submission_propagated.tsv")
    print("  2. Submit to Kaggle")
    print("  3. Wait for evaluation")

if __name__ == "__main__":
    main()