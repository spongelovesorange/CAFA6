#!/usr/bin/env python3
"""
CAFA6 GO Hierarchy Propagation - ä¿®å¤ç‰ˆæœ¬
ä¸»è¦ä¿®å¤ï¼š
1. ä¼ æ’­åªå¢žåŠ é¢„æµ‹ï¼Œä¸åˆ é™¤
2. ä½¿ç”¨æ›´åˆç†çš„é˜ˆå€¼
3. æ­£ç¡®çš„ç¥–å…ˆèŠ‚ç‚¹åˆ†æ•°è®¡ç®—
4. ä¿æŒè¶³å¤Ÿçš„é¢„æµ‹æ•°ä»¥ä¿è¯recall
"""

import os
import pandas as pd
import numpy as np
import csv
from goatools.obo_parser import GODag
from tqdm import tqdm

# ================= é…ç½® =================
INPUT_SUBMISSION = 'submission.tsv'
OUTPUT_SUBMISSION = 'submission_propagated.tsv'
OBO_PATH = 'data/Train/go-basic.obo'

# ================= ä¿®å¤åŽçš„ä¼ æ’­å‚æ•° =================
# å…³é”®æ”¹å˜ï¼š
# 1. é™ä½Žæœ€ç»ˆé˜ˆå€¼ï¼Œä¿ç•™æ›´å¤šé¢„æµ‹
# 2. å¢žåŠ æœ€å¤§é¢„æµ‹æ•°
# 3. ä¼ æ’­decayä¸è¦å¤ªæ¿€è¿›

PROPAGATION_MODE = 'max_inheritance'    # ä¼ æ’­åˆ°æ‰€æœ‰ç¥–å…ˆï¼Œä¸åªæ˜¯ç›´æŽ¥çˆ¶èŠ‚ç‚¹
PROPAGATION_DECAY = 0.85              # æ¯å±‚è¡°å‡15%
FINAL_THRESHOLD = 0.001                # æœ€ç»ˆè¿‡æ»¤é˜ˆå€¼ï¼ˆä»Ž0.06é™åˆ°0.01ï¼‰
MAX_PREDS_PER_PROTEIN = 1500          # æœ€å¤§é¢„æµ‹æ•°ï¼ˆä»Ž300å¢žåˆ°1000ï¼‰
MIN_PROPAGATED_SCORE = 0.01           # ä¼ æ’­çš„æœ€å°åˆ†æ•°


def get_all_ancestors(go_dag, term):
    """èŽ·å–GO termçš„æ‰€æœ‰ç¥–å…ˆèŠ‚ç‚¹"""
    try:
        if term in go_dag:
            return go_dag[term].get_all_parents()
        return set()
    except:
        return set()


def get_direct_parents(go_dag, term):
    """åªèŽ·å–ç›´æŽ¥çˆ¶èŠ‚ç‚¹"""
    try:
        if term in go_dag:
            return set(parent.id for parent in go_dag[term].parents)
        return set()
    except:
        return set()


def propagate_scores(protein_predictions, go_dag):
    """
    CAFA æ ‡å‡†ä¼ æ’­é€»è¾‘ï¼šMax Rule
    çˆ¶èŠ‚ç‚¹åˆ†æ•° = max(åŽŸåˆ†æ•°, max(å­èŠ‚ç‚¹åˆ†æ•°))
    ä¸éœ€è¦ decayï¼Œå› ä¸ºæˆ‘ä»¬è¦å®Œå…¨ä¿¡ä»»å­èŠ‚ç‚¹çš„è¯æ®ã€‚
    """
    # 1. åˆå§‹åŒ–æ‰€æœ‰æ¶‰åŠåˆ°çš„èŠ‚ç‚¹
    # ä½¿ç”¨å­—å…¸å­˜å‚¨æœ€ç»ˆåˆ†æ•°ï¼Œåˆå§‹å€¼ä¸ºåŽŸå§‹é¢„æµ‹å€¼
    final_scores = dict(protein_predictions)
    
    # 2. æ‹“æ‰‘æŽ’åºä¼ æ’­ (ä»Žå­èŠ‚ç‚¹å‘çˆ¶èŠ‚ç‚¹)
    # ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å¯ä»¥å¤šè½®è¿­ä»£æˆ–è€…é€šè¿‡èŽ·å–æ‰€æœ‰ç¥–å…ˆæ¥å¤„ç†
    # è¿™é‡Œä½¿ç”¨"æ‰€æœ‰ç¥–å…ˆ"çš„æ–¹å¼ï¼Œè™½ç„¶è®¡ç®—é‡å¤§ï¼Œä½†é€»è¾‘æœ€ç®€å•ä¸”æ­£ç¡®
    
    # å»ºç«‹ä¸€ä¸ªä¸´æ—¶çš„æ›´æ–°å­—å…¸ï¼Œé¿å…åœ¨éåŽ†æ—¶ä¿®æ”¹
    updates = {}
    
    for term, score in protein_predictions.items():
        # èŽ·å–è¯¥ term çš„æ‰€æœ‰ç¥–å…ˆ
        ancestors = get_all_ancestors(go_dag, term)
        
        for ancestor in ancestors:
            # ç¥–å…ˆçš„åˆ†æ•°è‡³å°‘åº”è¯¥æ˜¯å½“å‰å­èŠ‚ç‚¹çš„åˆ†æ•°
            # CAFA è§„åˆ™ï¼šS(parent) >= S(child)
            if ancestor in updates:
                updates[ancestor] = max(updates[ancestor], score)
            else:
                updates[ancestor] = score
    
    # 3. åˆå¹¶æ›´æ–°
    for term, score in updates.items():
        if term in final_scores:
            final_scores[term] = max(final_scores[term], score)
        else:
            final_scores[term] = score
            
    return final_scores

def main():
    print("="*80)
    print("ðŸŽ¯ CAFA6 GO Propagation - Fixed Version")
    print("="*80)
    
    print(f"\nðŸ“‹ Configuration:")
    print(f"   Mode:                 {PROPAGATION_MODE}")
    print(f"   Decay factor:         {PROPAGATION_DECAY}")
    print(f"   Min propagated score: {MIN_PROPAGATED_SCORE}")
    print(f"   Final threshold:      {FINAL_THRESHOLD}")
    print(f"   Max preds/protein:    {MAX_PREDS_PER_PROTEIN}")
    
    # 1. åŠ è½½GOå›¾
    print(f"\n>>> Loading GO DAG from {OBO_PATH}...")
    if not os.path.exists(OBO_PATH):
        print(f"âŒ GO OBO file not found: {OBO_PATH}")
        print("   Please download from: http://geneontology.org/docs/download-ontology/")
        return
    
    go_dag = GODag(OBO_PATH)
    print(f"âœ… GO DAG loaded: {len(go_dag)} terms")
    
    # 2. è¯»å–åŽŸå§‹æäº¤
    print(f"\n>>> Reading raw submission: {INPUT_SUBMISSION}...")
    if not os.path.exists(INPUT_SUBMISSION):
        print(f"âŒ Submission file not found: {INPUT_SUBMISSION}")
        return
    
    df = pd.read_csv(INPUT_SUBMISSION, sep='\t', names=['id', 'term', 'score'])
    print(f"âœ… Input: {len(df):,} predictions for {df['id'].nunique():,} proteins")
    
    # åŽŸå§‹ç»Ÿè®¡
    original_avg_preds = len(df) / df['id'].nunique()
    print(f"   Original avg preds/protein: {original_avg_preds:.1f}")
    
    # 3. è¿‡æ»¤æ— æ•ˆGO terms
    valid_terms = set(go_dag.keys())
    before_filter = len(df)
    df = df[df['term'].isin(valid_terms)]
    
    if before_filter != len(df):
        print(f"âš ï¸  Filtered {before_filter - len(df)} invalid GO terms")
    
    # 4. ä¼ æ’­
    grouped = df.groupby('id')
    new_rows = []
    
    stats = {
        'proteins_processed': 0,
        'preds_before': 0,
        'preds_after': 0,
        'preds_added': 0,
        'preds_from_propagation': 0
    }
    
    print(f"\n>>> Propagating GO terms...")
    for pid, group in tqdm(grouped, total=len(grouped)):
        # æž„å»ºåŽŸå§‹é¢„æµ‹å­—å…¸
        original_scores = dict(zip(group['term'], group['score']))
        stats['preds_before'] += len(original_scores)
        
        # ä¼ æ’­
        propagated_scores = propagate_scores(
            original_scores, 
            go_dag
        )
        
        # ç»Ÿè®¡æ–°å¢žçš„é¢„æµ‹
        new_terms = set(propagated_scores.keys()) - set(original_scores.keys())
        stats['preds_from_propagation'] += len(new_terms)
        
        # åº”ç”¨æœ€ç»ˆé˜ˆå€¼ï¼ˆåªè¿‡æ»¤å¤ªä½Žçš„åˆ†æ•°ï¼‰
        final_scores = {
            term: score 
            for term, score in propagated_scores.items() 
            if score >= FINAL_THRESHOLD
        }
        
        # å¦‚æžœé¢„æµ‹å¤ªå¤šï¼Œä¿ç•™Top-K
        if len(final_scores) > MAX_PREDS_PER_PROTEIN:
            sorted_items = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)
            final_scores = dict(sorted_items[:MAX_PREDS_PER_PROTEIN])
        
        stats['preds_after'] += len(final_scores)
        stats['preds_added'] += (len(final_scores) - len(original_scores))
        stats['proteins_processed'] += 1
        
        # æŒ‰åˆ†æ•°é™åºæŽ’åˆ—å¹¶æ·»åŠ åˆ°ç»“æžœ
        for term, score in sorted(final_scores.items(), key=lambda x: x[1], reverse=True):
            new_rows.append([pid, term, f"{score:.3f}"])
    
    print(f"âœ… Propagation complete")
    
    # 5. ä¿å­˜
    print(f"\n>>> Saving to {OUTPUT_SUBMISSION}...")
    with open(OUTPUT_SUBMISSION, 'w', newline='') as f:
        writer = csv.writer(f, delimiter='\t')
        writer.writerows(new_rows)
    print(f"âœ… File saved")
    
    # 6. éªŒè¯å’Œç»Ÿè®¡
    print("\n" + "="*80)
    print("ðŸ“Š PROPAGATION REPORT")
    print("="*80)
    
    df_final = pd.read_csv(OUTPUT_SUBMISSION, sep='\t', names=['id', 'term', 'score'])
    file_size_mb = os.path.getsize(OUTPUT_SUBMISSION) / (1024*1024)
    
    print(f"\nðŸ“ˆ Statistics:")
    print(f"   Proteins processed:    {stats['proteins_processed']:,}")
    print(f"   Predictions before:    {stats['preds_before']:,}")
    print(f"   Predictions after:     {stats['preds_after']:,}")
    print(f"   Added by propagation:  {stats['preds_from_propagation']:,}")
    print(f"   Net change:            {stats['preds_added']:+,}")
    
    print(f"\nðŸ“ˆ Final File Statistics:")
    print(f"   Total predictions:     {len(df_final):,}")
    print(f"   Unique proteins:       {df_final['id'].nunique():,}")
    print(f"   Unique GO terms:       {df_final['term'].nunique():,}")
    print(f"   Avg preds/protein:     {len(df_final) / df_final['id'].nunique():.1f}")
    print(f"   Score range:           [{df_final['score'].min():.3f}, {df_final['score'].max():.3f}]")
    print(f"   Score median:          {df_final['score'].median():.3f}")
    print(f"   ðŸ“ File size:          {file_size_mb:.1f} MB")
    
    # é¢„æµ‹æ•°åˆ†å¸ƒ
    counts = df_final.groupby('id').size()
    print(f"\nðŸ“Š Predictions per Protein:")
    print(f"   Min:     {counts.min()}")
    print(f"   10%:     {counts.quantile(0.10):.0f}")
    print(f"   25%:     {counts.quantile(0.25):.0f}")
    print(f"   Median:  {counts.median():.0f}")
    print(f"   75%:     {counts.quantile(0.75):.0f}")
    print(f"   90%:     {counts.quantile(0.90):.0f}")
    print(f"   Max:     {counts.max()}")
    print(f"   Mean:    {counts.mean():.1f}")
    
    # ä¼ æ’­æ•ˆæžœ
    final_avg = len(df_final) / df_final['id'].nunique()
    growth = (final_avg / original_avg_preds - 1) * 100
    
    print(f"\nðŸ“ˆ Propagation Effect:")
    print(f"   Before:  {original_avg_preds:.1f} preds/protein")
    print(f"   After:   {final_avg:.1f} preds/protein")
    print(f"   Growth:  {growth:+.1f}%")
    
    # æ–‡ä»¶å¤§å°æ£€æŸ¥
    print(f"\nðŸ“ File Size Check:")
    if file_size_mb > 800:
        print(f"   âš ï¸  Large file ({file_size_mb:.0f} MB)")
        print(f"   Consider increasing FINAL_THRESHOLD or decreasing MAX_PREDS_PER_PROTEIN")
    else:
        print(f"   âœ… File size OK ({file_size_mb:.0f} MB)")
    
    # æ€§èƒ½ä¼°è®¡
    print(f"\nðŸŽ¯ Expected Performance:")
    score_median = df_final['score'].median()
    
    if final_avg > 100 and score_median > 0.05:
        print(f"   Strategy:        Balanced (good recall + precision)")
        print(f"   Expected F-max:  0.32-0.40 âœ…")
    elif final_avg > 50:
        print(f"   Strategy:        Conservative")
        print(f"   Expected F-max:  0.28-0.36")
    else:
        print(f"   Strategy:        Very Conservative")
        print(f"   Expected F-max:  0.25-0.32")
    
    print("\n" + "="*80)
    print(f"âœ… PROPAGATION COMPLETE!")
    print(f"   Output: {OUTPUT_SUBMISSION}")
    print(f"   Size:   {file_size_mb:.1f} MB")
    print(f"   Ready for submission to Kaggle")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()