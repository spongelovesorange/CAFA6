import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from peft import PeftModel
import numpy as np
from Bio import SeqIO
from tqdm import tqdm
import pickle
import gzip
import gc

# === é…ç½® ===
MODEL_PATH = "models/esm2_t36_3B_UR50D"
ADAPTER_PATH = "models/checkpoints_esm2_3b_asl/final_esm2_3b_asl" 
TEST_FASTA = "data/Test/testsuperset.fasta"
LABEL_MAP = "models/checkpoints_esm2_3b_asl/label_map.pkl"
# è¾“å‡ºæ”¹ä¸º .tsv.gz
OUTPUT_FILE = "predictions/esm2_raw.tsv.gz"
BATCH_SIZE = 64
MAX_LEN = 1024 
# é˜ˆå€¼è®¾æžä½Žï¼Œä¿ç•™æ‰€æœ‰å¯èƒ½çš„ä¿¡å·ä¾›åŽç»­èžåˆå’Œä¼ æ’­ä½¿ç”¨
THRESHOLD = 0.0001 

def predict():
    print(f"ðŸš€ åŠ è½½ ESM2 æ¨¡åž‹...")
    with open(LABEL_MAP, "rb") as f:
        term2idx = pickle.load(f)
    idx2term = {v: k for k, v in term2idx.items()}
    num_labels = len(term2idx)

    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
    base_model = AutoModelForSequenceClassification.from_pretrained(
        MODEL_PATH, num_labels=num_labels, torch_dtype=torch.bfloat16, device_map="cuda:0"
    )
    model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)
    model.eval()

    print("ðŸ“¥ è¯»å–å¹¶æŽ’åºåºåˆ—...")
    sequences, ids = [], []
    for record in SeqIO.parse(TEST_FASTA, "fasta"):
        # ID æ¸…æ´—é€»è¾‘
        header = record.id
        pid = header.split('|')[1] if "|" in header else header.split()[0]
        sequences.append(str(record.seq)[:MAX_LEN])
        ids.append(pid)
    
    # é•¿åº¦æŽ’åºæé€Ÿ
    sorted_indices = np.argsort([len(s) for s in sequences])
    sequences = [sequences[i] for i in sorted_indices]
    ids = [ids[i] for i in sorted_indices]
    
    print(f"âš¡ å¼€å§‹æŽ¨ç† -> {OUTPUT_FILE}")
    
    # ä½¿ç”¨ gzip å†™å…¥ï¼Œæ–‡æœ¬æ¨¡å¼ (wt)
    with gzip.open(OUTPUT_FILE, "wt") as f_out:
        with torch.no_grad():
            for i in tqdm(range(0, len(sequences), BATCH_SIZE)):
                batch_seqs = sequences[i:i+BATCH_SIZE]
                batch_ids = ids[i:i+BATCH_SIZE]

                inputs = tokenizer(batch_seqs, return_tensors="pt", padding=True, truncation=True, max_length=MAX_LEN).to("cuda")
                logits = model(**inputs).logits
                probs = torch.sigmoid(logits).float().cpu().numpy()

                lines = []
                for j, pid in enumerate(batch_ids):
                    # åªè¦å¤§äºŽ 0.0001 çš„éƒ½ç•™ç€
                    indices = np.where(probs[j] > THRESHOLD)[0]
                    for idx in indices:
                        score = probs[j][idx]
                        lines.append(f"{pid}\t{idx2term[idx]}\t{score:.5f}\n")
                
                f_out.writelines(lines)
                del inputs, logits, probs
                if i % 1000 == 0: gc.collect()

if __name__ == "__main__":
    predict()